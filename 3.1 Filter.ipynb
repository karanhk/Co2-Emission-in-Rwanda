{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91131833",
   "metadata": {},
   "source": [
    "<font color='red'><h1> Workbook for filter feature engineering </h1></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d67bd",
   "metadata": {},
   "source": [
    "This workbook does feature engineering on row data, it applies feature selectiona and feature extraction. This workbook is to\n",
    "1. Select features based on filter methods\n",
    "2. Extract features based on PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439286f9",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6eef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf830b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.getcwd() + \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46af9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(csv_path + \"train.csv\")\n",
    "val_df = pd.read_csv(csv_path + \"val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b17ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('emission',axis=1)\n",
    "y_train = train_df['emission']\n",
    "X_val = val_df.drop('emission',axis=1)\n",
    "y_val = val_df['emission']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120cf36",
   "metadata": {},
   "source": [
    "## Feature Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3138310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names of the DataFrame\n",
    "columns = corr_matrix.columns\n",
    "\n",
    "# Create an empty list to keep track of columns to drop\n",
    "drop_cols = []\n",
    "\n",
    "# Loop over the columns\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i + 1, len(columns)):\n",
    "        # Access the cell of the DataFrame\n",
    "        if corr_matrix.loc[columns[i], columns[j]] > 0.9:\n",
    "            drop_cols.append(columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8597d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = set(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f1 = X_train.drop(columns = drop_cols, axis = 1)\n",
    "X_val_f1 = X_val.drop(columns = drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f1['emission'] = y_train\n",
    "X_val_f1['emission'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f1.to_csv(csv_path + \"train_f1.csv\",index=False)\n",
    "X_val_f1.to_csv(csv_path + \"val_f1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77928c33",
   "metadata": {},
   "source": [
    "## Feature Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18401e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d16b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names of the DataFrame\n",
    "columns = corr_matrix.columns\n",
    "\n",
    "# Create an empty list to keep track of columns to drop\n",
    "drop_cols_dict = {}\n",
    "drop_cols_set = set()\n",
    "drop_cols_list = []\n",
    "\n",
    "# Loop over the columns\n",
    "for i in range(len(columns)):\n",
    "    \n",
    "    drop_cols_list = []\n",
    "    if columns[i] in drop_cols_set:\n",
    "        continue\n",
    "        \n",
    "    for j in range(i + 1, len(columns)):\n",
    "        \n",
    "        if columns[j] in drop_cols_set:\n",
    "            continue\n",
    "            \n",
    "        if corr_matrix.loc[columns[i], columns[j]] > 0.8:\n",
    "            if columns[i] in drop_cols_dict:\n",
    "                drop_cols_list = drop_cols_dict[columns[i]]\n",
    "                drop_cols_list.append(columns[j])\n",
    "                drop_cols_dict[columns[i]] = drop_cols_list\n",
    "                \n",
    "            else:\n",
    "                drop_cols_list.append(columns[i])\n",
    "                drop_cols_list.append(columns[j])\n",
    "                drop_cols_dict[columns[i]] = drop_cols_list\n",
    "            \n",
    "            drop_cols_set.add(columns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d51d0f",
   "metadata": {},
   "source": [
    "## Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60de913",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in drop_cols_dict:\n",
    "    col_set = drop_cols_dict[col]\n",
    "    sample_df_train = train_df[col_set]\n",
    "    sample_df_val = val_df[col_set]\n",
    "    \n",
    "    n_components = 1\n",
    "    \n",
    "    if len(col_set) > 3:\n",
    "        n_components = 3\n",
    "        \n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca_train = pca.fit_transform(sample_df_train)\n",
    "    X_pca_val = pca.fit_transform(sample_df_val)\n",
    "    \n",
    "    \n",
    "    for i in range(X_pca_train.shape[1]):\n",
    "        train_df[col+'_'+str(i)] = X_pca_train[:,i]\n",
    "        val_df[col+'_'+str(i)] = X_pca_val[:,i]\n",
    "        \n",
    "    train_df.drop(columns=col_set,inplace=True)  \n",
    "    val_df.drop(columns=col_set,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec18f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(csv_path + \"train_f2.csv\",index=False)\n",
    "val_df.to_csv(csv_path+\"val_f2.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
